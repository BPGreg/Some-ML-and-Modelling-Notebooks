{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Plantnet Classification\n\n*Andrieu Grégoire & Gille Cyprien*","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport os\nimport pandas as pd\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nimport torchvision.transforms.functional as TF\nfrom PIL import Image\nfrom torch.utils.data import DataLoader, Subset, WeightedRandomSampler, random_split\nfrom sklearn.model_selection import train_test_split\nimport torch.nn.functional as F\nfrom tqdm.notebook import tqdm\nimport copy\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:06.126196Z","iopub.execute_input":"2021-11-28T16:13:06.126877Z","iopub.status.idle":"2021-11-28T16:13:08.531556Z","shell.execute_reply.started":"2021-11-28T16:13:06.126752Z","shell.execute_reply":"2021-11-28T16:13:08.53084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"train_dir_path = \"../input/polytech-nice-data-science-course-2021/polytech/train\"","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:08.53314Z","iopub.execute_input":"2021-11-28T16:13:08.534308Z","iopub.status.idle":"2021-11-28T16:13:08.538299Z","shell.execute_reply.started":"2021-11-28T16:13:08.534268Z","shell.execute_reply":"2021-11-28T16:13:08.537658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA","metadata":{}},{"cell_type":"code","source":"# Put here EDA that shows that the classes are unbalanced, and data augmentation to fix this problem \n# cf http://pytorch.org/vision/main/transforms.html#automatic-augmentation-transforms","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:08.539428Z","iopub.execute_input":"2021-11-28T16:13:08.540173Z","iopub.status.idle":"2021-11-28T16:13:08.548163Z","shell.execute_reply.started":"2021-11-28T16:13:08.540134Z","shell.execute_reply":"2021-11-28T16:13:08.547483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All the classes\nclasses = os.listdir(train_dir_path)\n\n# compute the number of images per class\nnums = {}\nfor plant_num in classes:\n    nums[str(plant_num)] = len(os.listdir(train_dir_path + '/' + plant_num))\n\nimg_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"number of images\"])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:08.549554Z","iopub.execute_input":"2021-11-28T16:13:08.549823Z","iopub.status.idle":"2021-11-28T16:13:13.743266Z","shell.execute_reply.started":"2021-11-28T16:13:08.549786Z","shell.execute_reply":"2021-11-28T16:13:13.7425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = [i for i in range(153)]\nplt.figure(figsize=(15, 6))\nplt.bar(index, [n for n in nums.values()], width=0.4)\nplt.xlabel('Classes (random order)')\nplt.ylabel('Quantity of images available')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:13.745683Z","iopub.execute_input":"2021-11-28T16:13:13.746208Z","iopub.status.idle":"2021-11-28T16:13:14.227195Z","shell.execute_reply.started":"2021-11-28T16:13:13.746159Z","shell.execute_reply":"2021-11-28T16:13:14.226457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_per_class.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:14.228316Z","iopub.execute_input":"2021-11-28T16:13:14.22911Z","iopub.status.idle":"2021-11-28T16:13:14.255839Z","shell.execute_reply.started":"2021-11-28T16:13:14.22907Z","shell.execute_reply":"2021-11-28T16:13:14.255045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Oversampling et Data Augmentation","metadata":{}},{"cell_type":"code","source":"# when getting from the under-represented classes, transform (to avoid always giving the same images maybe)\n\nclass SmartAugmentationDataset(ImageFolder):\n    def __init__(self, path, transform=None, aug_class_id=None):\n        super().__init__(path, transforms.Compose([transforms.Resize([183, 183]), transforms.ToTensor()]))\n        self.transform = transform\n        self.aug_class_id = aug_class_id\n\n    def __len__(self):\n        return len(self.imgs)\n    \n    def __getitem__(self, index): \n        x, y = super().__getitem__(index)\n        \n        if self.aug_class_id is not None and self.transform is not None:\n            if y in self.aug_class_id:\n                x = self.transform(x)\n        \n        return x, y","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:14.25715Z","iopub.execute_input":"2021-11-28T16:13:14.25749Z","iopub.status.idle":"2021-11-28T16:13:14.264735Z","shell.execute_reply.started":"2021-11-28T16:13:14.25745Z","shell.execute_reply":"2021-11-28T16:13:14.264021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# figure out the indices of classes that need augmentation\naug_class_id = []\n\nfor id in range(1, 154):\n    n_img = nums.get(str(id))\n    if n_img < 927: # 75% des classes (3eme quartile)\n        aug_class_id.append(id)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:14.266173Z","iopub.execute_input":"2021-11-28T16:13:14.266876Z","iopub.status.idle":"2021-11-28T16:13:14.274735Z","shell.execute_reply.started":"2021-11-28T16:13:14.266838Z","shell.execute_reply":"2021-11-28T16:13:14.274014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data augmentation transform\nclass RandomFlipsTransform:\n\n    def __init__(self, identity_proba=0.5) -> None:\n        self.identity_proba = identity_proba\n\n    def __call__(self, img):\n        if torch.rand(1) < self.identity_proba:\n            return img\n        return self.change_image(img)\n\n    def change_image(self, img):\n        p = torch.rand(1)\n        if p < 0.25:\n            return TF.rotate(img, 90)\n        elif p < 0.5:\n            return TF.rotate(img, 180)\n        elif p < 0.75:\n            return TF.rotate(img, 270)\n        return TF.gaussian_blur(img, 3)\n        \n\n\naug_transforms = RandomFlipsTransform(0.66)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:14.27613Z","iopub.execute_input":"2021-11-28T16:13:14.276653Z","iopub.status.idle":"2021-11-28T16:13:14.2873Z","shell.execute_reply.started":"2021-11-28T16:13:14.276614Z","shell.execute_reply":"2021-11-28T16:13:14.286463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading et splitting des données","metadata":{}},{"cell_type":"code","source":"dataset = ImageFolder(train_dir_path, transforms.Compose([transforms.Resize([183, 183]), transforms.ToTensor()]))\n# dataset = SmartAugmentationDataset(train_dir_path, transform=aug_transforms, aug_class_id=aug_class_id)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:14.289043Z","iopub.execute_input":"2021-11-28T16:13:14.289384Z","iopub.status.idle":"2021-11-28T16:13:51.692434Z","shell.execute_reply.started":"2021-11-28T16:13:14.289349Z","shell.execute_reply":"2021-11-28T16:13:51.691678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_proportion = 0.9\n# train_len = int(len(dataset)*train_proportion)\n# valid_len = len(dataset) - train_len\n\n# train_split, valid_split = random_split(dataset, [train_len, valid_len])\n\n\n# split les indices\ntrain_indices, valid_indices, _, _ = train_test_split(\n    range(len(dataset)),\n    dataset.targets,\n    stratify=dataset.targets,\n    test_size=1 - train_proportion\n)\n\n# split le dataset avec les indices\ntrain_split = Subset(dataset, train_indices)\nvalid_split = Subset(dataset, valid_indices)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:51.797693Z","iopub.execute_input":"2021-11-28T16:13:51.797947Z","iopub.status.idle":"2021-11-28T16:13:51.827628Z","shell.execute_reply.started":"2021-11-28T16:13:51.797912Z","shell.execute_reply":"2021-11-28T16:13:51.826921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights = {int(class_name):1/class_len for (class_name, class_len) in nums.items()}","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:13:51.851582Z","iopub.execute_input":"2021-11-28T16:13:51.851821Z","iopub.status.idle":"2021-11-28T16:13:51.860358Z","shell.execute_reply.started":"2021-11-28T16:13:51.851791Z","shell.execute_reply":"2021-11-28T16:13:51.859693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_weights = []\nfor i in tqdm(range(len(train_split))):\n    _, y = train_split.__getitem__(i)\n    sample_weights.append(class_weights[y+1])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:16:32.620532Z","iopub.execute_input":"2021-11-28T16:16:32.6208Z","iopub.status.idle":"2021-11-28T16:32:40.032415Z","shell.execute_reply.started":"2021-11-28T16:16:32.62077Z","shell.execute_reply":"2021-11-28T16:32:40.031645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 16 # valeur un peu au hasard pour le moment\n","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:54:40.476293Z","iopub.execute_input":"2021-11-28T16:54:40.476952Z","iopub.status.idle":"2021-11-28T16:54:40.481799Z","shell.execute_reply.started":"2021-11-28T16:54:40.476908Z","shell.execute_reply":"2021-11-28T16:54:40.480825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# num workers = 2 parce que le cpu de kaggle a 2 cores (2-core Intel(R) Xeon(R) CPU @ 2.30GHz)\n# pin memory pour rendre les epoch plus rapide apres la premiere (bof)\n\n# pas besoin de shuffle le validation set vu que l'eval est pas influencee par l'ordre des batches\n\ntrain_sampler = WeightedRandomSampler(sample_weights, 2*len(sample_weights), replacement=True)\ntrain_dl = DataLoader(train_split, batch_size, num_workers=2, sampler=train_sampler)\nvalid_dl = DataLoader(valid_split, batch_size, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:35:58.103144Z","iopub.execute_input":"2021-11-28T16:35:58.103661Z","iopub.status.idle":"2021-11-28T16:35:58.109777Z","shell.execute_reply.started":"2021-11-28T16:35:58.103624Z","shell.execute_reply":"2021-11-28T16:35:58.109122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:36:21.986604Z","iopub.execute_input":"2021-11-28T16:36:21.987147Z","iopub.status.idle":"2021-11-28T16:36:21.991384Z","shell.execute_reply.started":"2021-11-28T16:36:21.987108Z","shell.execute_reply":"2021-11-28T16:36:21.990551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Pour ne pas avoir a choisir \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:36:22.949965Z","iopub.execute_input":"2021-11-28T16:36:22.950595Z","iopub.status.idle":"2021-11-28T16:36:22.955679Z","shell.execute_reply.started":"2021-11-28T16:36:22.950554Z","shell.execute_reply":"2021-11-28T16:36:22.954618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Network","metadata":{}},{"cell_type":"code","source":"# calcul de la justesse du modele\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\n\n# general model methods\nclass PlantNetModel(nn.Module):\n    \n    def batch_training(self, batch):\n        imgs, labels = batch\n        out = self(imgs)\n        loss = F.cross_entropy(out, labels)\n        return loss\n    \n    def batch_evaluation(self, batch):\n        imgs, labels = batch\n        out = self(imgs)\n        loss = F.cross_entropy(out, labels)\n        acc = accuracy(out, labels)\n        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n    \n    def eval_epoch(self, outputs):\n        batch_losses = [x[\"val_loss\"] for x in outputs]\n        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()  \n        epoch_accuracy = torch.stack(batch_accuracy).mean()\n        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy}\n    \n    \n    def print_epoch_end(self, epoch, result):\n        print((f\"\"\"Epoch [{epoch+1}],\n        train_loss: {result['train_loss']}, \n        val_loss: {result['val_loss']}, \n        val_acc: {result['val_accuracy']}\"\"\")\n        )","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:36:26.050502Z","iopub.execute_input":"2021-11-28T16:36:26.051332Z","iopub.status.idle":"2021-11-28T16:36:26.062393Z","shell.execute_reply.started":"2021-11-28T16:36:26.051285Z","shell.execute_reply":"2021-11-28T16:36:26.061558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NB: could try to add dropout layers down there","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:36:26.854914Z","iopub.execute_input":"2021-11-28T16:36:26.855211Z","iopub.status.idle":"2021-11-28T16:36:26.859014Z","shell.execute_reply.started":"2021-11-28T16:36:26.85518Z","shell.execute_reply":"2021-11-28T16:36:26.85804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convolution block avec BatchNormalization\ndef ConvBlock(in_channels, out_channels, pool=False, kernel_size=3, padding=1, stride=1, pooling_kernel_size=3):\n    \n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool:\n        layers.append(nn.MaxPool2d(pooling_kernel_size))\n    return nn.Sequential(*layers)\n\n# simpler net\nclass ConvNet(PlantNetModel):\n    def __init__(self, in_channels, n_classes):\n        super().__init__()\n        \n        self.conv1 = ConvBlock(in_channels, 64)\n        self.conv2 = ConvBlock(64, 128, pool=True) # 128x61x61\n        \n        \n        self.conv3 = ConvBlock(128, 256, pool=True) # 256 x 20 x 20\n        self.conv4 = ConvBlock(256, 512, pool=True) # 512 x 6 x 6\n        self.conv5 = ConvBlock(512, 512, pool=True) # 512 x 2 x 2\n        \n        self.dropout = nn.Dropout(p=0.1) \n        \n        self.classif = nn.Sequential(nn.MaxPool2d(2),\n                                     nn.Flatten(),\n                                     nn.Linear(512, n_classes))\n        \n    def forward(self, batch):\n        out = self.conv1(batch)\n        out = self.conv2(out)\n        out = self.dropout(out)\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.dropout(out)\n        out = self.conv5(out)\n        out = self.classif(out)\n        return out\n\n# net architecture \nclass ResNet(PlantNetModel):\n    def __init__(self, in_channels, n_classes):\n        super().__init__()\n        \n        self.conv1 = ConvBlock(in_channels, 32)\n        self.conv2 = ConvBlock(32, 64, pool=True) # 64x61x61\n        self.conv3 = ConvBlock(64, 128, pool=True) # 128 x 20 x 20\n        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128), ConvBlock(128, 128))\n\n        self.conv4 = ConvBlock(128, 256, pool=True) # 256 x 6 x 6\n        self.conv5 = ConvBlock(256, 256, pool=True, pooling_kernel_size=2) # 256 x 3 x 3\n        self.res2 = nn.Sequential(ConvBlock(256, 256), ConvBlock(256, 256), ConvBlock(256, 256))\n        \n        self.classif = nn.Sequential(nn.MaxPool2d(3),\n                                     nn.Flatten(),\n                                     nn.Linear(256, n_classes))\n        \n        self.dropout = nn.Dropout(p=0.1)\n        \n    def forward(self, batch):\n        out = self.conv1(batch)\n        out = self.conv2(out)\n        out = self.conv3(out)\n        out = self.res1(out) + out\n        out = self.dropout(out)\n        out = self.conv4(out)\n        out = self.dropout(out)\n        out = self.conv5(out)\n        out = self.dropout(out)\n        out = self.res2(out) + out\n        out = self.classif(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:36:27.246394Z","iopub.execute_input":"2021-11-28T16:36:27.247002Z","iopub.status.idle":"2021-11-28T16:36:27.25938Z","shell.execute_reply.started":"2021-11-28T16:36:27.246947Z","shell.execute_reply":"2021-11-28T16:36:27.258671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"model = ConvNet(3, len(dataset.classes))\n# model = ResNet(3, len(dataset.classes))\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:56:57.60853Z","iopub.execute_input":"2021-11-28T16:56:57.609086Z","iopub.status.idle":"2021-11-28T16:56:57.658024Z","shell.execute_reply.started":"2021-11-28T16:56:57.609048Z","shell.execute_reply":"2021-11-28T16:56:57.657139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"best_model.pt\") # save the untrained model on sait jamais","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:57:25.662095Z","iopub.execute_input":"2021-11-28T16:57:25.662769Z","iopub.status.idle":"2021-11-28T16:57:25.701125Z","shell.execute_reply.started":"2021-11-28T16:57:25.662732Z","shell.execute_reply":"2021-11-28T16:57:25.700288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for training\n@torch.no_grad()\ndef evaluate(model, val_dl, prog_bar=False):\n    model.eval() # evaluation mode\n    if prog_bar:\n        outputs = [model.batch_evaluation(to_device(batch, device)) for batch in tqdm(val_dl)]\n    else:\n        outputs = [model.batch_evaluation(to_device(batch, device)) for batch in val_dl]\n    return model.eval_epoch(outputs)\n    \n    \ndef full_training(epochs, \n                  lr, \n                  model, \n                  train_dl, \n                  val_loader, \n                  weight_decay=0, \n                  grad_clip=None, \n                  optimizer=torch.optim.SGD):\n    \n    torch.cuda.empty_cache()\n    history = []\n    best_val_acc = 0\n    \n    optimizer = optimizer(model.parameters(), lr, weight_decay=weight_decay)\n    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, mode=\"max\", verbose=True)\n    # sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, verbose=True)\n    \n    for epoch in range(epochs):\n        # Training\n        # print(f\"Started training epoch {epoch+1}...\")\n        model.train() # training mode\n        train_losses = []\n        for batch in tqdm(train_dl):\n            batch = to_device(batch, device)\n            \n            loss = model.batch_training(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # gradient clipping (pour le resnet)\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            optimizer.step()\n            optimizer.zero_grad()\n\n        # validation\n        result = evaluate(model, val_loader, prog_bar=False)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.print_epoch_end(epoch, result)\n        history.append(result)\n        vc = result[\"val_accuracy\"]\n        sched.step(vc) # for reduce lr on plateau\n        # sched.step()\n        if  vc > best_val_acc:\n            print(f\"Saving new best model from epoch {epoch+1} with val_acc of {vc}\\n\")\n            torch.save(model.state_dict(), \"best_model.pt\")\n    \n    return history","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:36:38.743956Z","iopub.execute_input":"2021-11-28T16:36:38.744383Z","iopub.status.idle":"2021-11-28T16:36:38.756485Z","shell.execute_reply.started":"2021-11-28T16:36:38.744347Z","shell.execute_reply":"2021-11-28T16:36:38.755666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nlr = 0.01\ngrad_clip = 5 # just in case there is a bad minibatch\n# weight_decay = 1e-4\noptim = torch.optim.Adam # voir si SGD ou Adamw marche mieux","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:36:40.646682Z","iopub.execute_input":"2021-11-28T16:36:40.647433Z","iopub.status.idle":"2021-11-28T16:36:40.65149Z","shell.execute_reply.started":"2021-11-28T16:36:40.647392Z","shell.execute_reply":"2021-11-28T16:36:40.650394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = [evaluate(model, valid_dl, prog_bar=True)]","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:36:40.977354Z","iopub.execute_input":"2021-11-28T16:36:40.977807Z","iopub.status.idle":"2021-11-28T16:41:55.695493Z","shell.execute_reply.started":"2021-11-28T16:36:40.977771Z","shell.execute_reply":"2021-11-28T16:41:55.694803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history # bad accuracy because the weights are still random","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:41:55.69791Z","iopub.execute_input":"2021-11-28T16:41:55.698212Z","iopub.status.idle":"2021-11-28T16:41:55.730038Z","shell.execute_reply.started":"2021-11-28T16:41:55.69817Z","shell.execute_reply":"2021-11-28T16:41:55.729241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history += full_training(epochs, lr, model, train_dl, valid_dl, grad_clip=grad_clip, optimizer=optim)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:41:55.731328Z","iopub.execute_input":"2021-11-28T16:41:55.731724Z","iopub.status.idle":"2021-11-28T16:43:25.643825Z","shell.execute_reply.started":"2021-11-28T16:41:55.731683Z","shell.execute_reply":"2021-11-28T16:43:25.642683Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Experiments","metadata":{}},{"cell_type":"markdown","source":"## Progress","metadata":{}},{"cell_type":"markdown","source":"- CNN, 10 epochs, lr=0.1, 5 blocs cnn et 1 bloc de sortie fcn : val_acc= 0.68","metadata":{}},{"cell_type":"code","source":"model = ResNet(3, len(dataset.classes))\nmodel.load_state_dict(torch.load(\"best_model.pt\"))\nmodel.cuda()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:58:13.362147Z","iopub.execute_input":"2021-11-28T16:58:13.362689Z","iopub.status.idle":"2021-11-28T16:58:13.427826Z","shell.execute_reply.started":"2021-11-28T16:58:13.362648Z","shell.execute_reply":"2021-11-28T16:58:13.427023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# we need to preserve order maybe ? update: we don't\norig_sub = pd.read_csv(\"../input/polytech-nice-data-science-course-2021/polytech/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:58:16.216898Z","iopub.execute_input":"2021-11-28T16:58:16.217614Z","iopub.status.idle":"2021-11-28T16:58:16.232798Z","shell.execute_reply.started":"2021-11-28T16:58:16.217576Z","shell.execute_reply":"2021-11-28T16:58:16.232123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred(img_name):\n    img = Image.open(\"../input/polytech-nice-data-science-course-2021/polytech/test/\" + img_name)\n    in_tr = transforms.Compose([transforms.Resize([183,183]), transforms.ToTensor()])\n    img = in_tr(img)\n    \n    img_batch = img.unsqueeze(0).cuda()\n    out = model(img_batch)\n    _, pred_class = torch.max(out, dim=1)\n    return pred_class","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:58:16.53536Z","iopub.execute_input":"2021-11-28T16:58:16.535969Z","iopub.status.idle":"2021-11-28T16:58:16.541654Z","shell.execute_reply.started":"2021-11-28T16:58:16.535932Z","shell.execute_reply":"2021-11-28T16:58:16.540629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(columns=[\"image_name\", \"class\"])\n\nfor i, img_name in enumerate(tqdm(orig_sub[\"image_name\"])):\n    submission.at[i, \"image_name\"] = img_name\n    submission.at[i, \"class\"] = dataset.classes[pred(img_name).item()]","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:58:17.259482Z","iopub.execute_input":"2021-11-28T16:58:17.260086Z","iopub.status.idle":"2021-11-28T16:58:23.48627Z","shell.execute_reply.started":"2021-11-28T16:58:17.260051Z","shell.execute_reply":"2021-11-28T16:58:23.48524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T16:58:25.938237Z","iopub.execute_input":"2021-11-28T16:58:25.93903Z","iopub.status.idle":"2021-11-28T16:58:25.948557Z","shell.execute_reply.started":"2021-11-28T16:58:25.938961Z","shell.execute_reply":"2021-11-28T16:58:25.947899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"class\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:03:20.566906Z","iopub.status.idle":"2021-11-24T17:03:20.567421Z","shell.execute_reply.started":"2021-11-24T17:03:20.56718Z","shell.execute_reply":"2021-11-24T17:03:20.567204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:03:20.568904Z","iopub.status.idle":"2021-11-24T17:03:20.569707Z","shell.execute_reply.started":"2021-11-24T17:03:20.569464Z","shell.execute_reply":"2021-11-24T17:03:20.569491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred(\"1.jpg\")","metadata":{"execution":{"iopub.status.busy":"2021-11-24T17:03:20.570923Z","iopub.status.idle":"2021-11-24T17:03:20.571731Z","shell.execute_reply.started":"2021-11-24T17:03:20.571487Z","shell.execute_reply":"2021-11-24T17:03:20.571517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion","metadata":{}}]}